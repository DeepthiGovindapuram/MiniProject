{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2f50b7b91e8d4ad6a129026e6e01f3f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ff3004da7504c648a257c09348a96bb",
              "IPY_MODEL_9da6e2459ae9427495599fd763e3b20d",
              "IPY_MODEL_f67bdebe7a6e49d987db549ebe8e426e"
            ],
            "layout": "IPY_MODEL_a7433ebf312743ddad6eb9a9f895e786"
          }
        },
        "1ff3004da7504c648a257c09348a96bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a163cab35534f05a9a3eb2d7707f723",
            "placeholder": "​",
            "style": "IPY_MODEL_1faebcb1d061419c82c189c839c90a9e",
            "value": "model.safetensors: 100%"
          }
        },
        "9da6e2459ae9427495599fd763e3b20d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2d73ece473d458b8158a44080d9424e",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2e88235b1674eb3ab164e0e13b6e1d3",
            "value": 498818054
          }
        },
        "f67bdebe7a6e49d987db549ebe8e426e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b16785b4c5c04496ab01690219e27325",
            "placeholder": "​",
            "style": "IPY_MODEL_627cebc8a7134673aef7e85c691e78fa",
            "value": " 499M/499M [00:06&lt;00:00, 112MB/s]"
          }
        },
        "a7433ebf312743ddad6eb9a9f895e786": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a163cab35534f05a9a3eb2d7707f723": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1faebcb1d061419c82c189c839c90a9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2d73ece473d458b8158a44080d9424e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2e88235b1674eb3ab164e0e13b6e1d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b16785b4c5c04496ab01690219e27325": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "627cebc8a7134673aef7e85c691e78fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U5abup4nhbR",
        "outputId": "ad31f64d-f965-4856-fe01-0a2b9e668296"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Google Drive mounting removed\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer # Importing TfidfVectorizer\n",
        "from imblearn.over_sampling import SMOTE # Importing SMOTE\n"
      ],
      "metadata": {
        "id": "gf7VNt1ZoLeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = [\n",
        "    pd.read_csv('/content/drive/MyDrive/Fake_Postings.csv'),\n",
        "    pd.read_csv('/content/drive/MyDrive/Pakistan_Job_Postings.csv'),\n",
        "    pd.read_csv('/content/drive/MyDrive/Job_Title_Des.csv')\n",
        "]"
      ],
      "metadata": {
        "id": "Vs9x0eNtpRjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets[1]['fraudulent'] = 0\n",
        "datasets[2]['fraudulent'] = 0\n",
        "\n",
        "\n",
        "df = pd.concat(datasets, ignore_index=True)\n",
        "df = df[['title', 'description', 'fraudulent']].dropna()\n",
        "df['text'] = df['title'] + ' ' + df['description']\n",
        "df['text_length'] = df['text'].apply(lambda x: len(x.split()))\n",
        "df = df[df['text_length'] > 5]\n",
        "X, y = df['text'], df['fraudulent']"
      ],
      "metadata": {
        "id": "sI_ASM-TphI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(datasets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAYgei-cpuih",
        "outputId": "4f5040b5-cd11-4b9a-be99-a9f5911ff026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[                                             title  \\\n",
            "0                              Mental health nurse   \n",
            "1                        Conference centre manager   \n",
            "2                                   Engineer, land   \n",
            "3                          Forest/woodland manager   \n",
            "4     Production designer, theatre/television/film   \n",
            "...                                            ...   \n",
            "9995                           Designer, furniture   \n",
            "9996                Therapist, speech and language   \n",
            "9997                             Therapist, sports   \n",
            "9998                   Clinical research associate   \n",
            "9999                           Hospital pharmacist   \n",
            "\n",
            "                                            description  \\\n",
            "0     Arm drive court sure vote. Earn $5000/week! Im...   \n",
            "1     Government whom its bed go tax tree black. Ear...   \n",
            "2     I member discuss follow way there nation. Earn...   \n",
            "3     House across wait approach face. Earn $5000/we...   \n",
            "4     Case best environmental full finally leader me...   \n",
            "...                                                 ...   \n",
            "9995  Worry own pressure stuff together room propert...   \n",
            "9996  Enter bit thing certainly. Earn $5000/week! Im...   \n",
            "9997  Visit goal under boy. Earn $5000/week! Immedia...   \n",
            "9998  Walk money letter few. Earn $5000/week! Immedi...   \n",
            "9999  Other left TV each reveal. Earn $5000/week! Im...   \n",
            "\n",
            "                                           requirements  \\\n",
            "0     Basic knowledge in live, no degree required. F...   \n",
            "1     Basic knowledge in seek, no degree required. F...   \n",
            "2     Basic knowledge in worker, no degree required....   \n",
            "3     Basic knowledge in example, no degree required...   \n",
            "4     Basic knowledge in smile, no degree required. ...   \n",
            "...                                                 ...   \n",
            "9995  Basic knowledge in discussion, no degree requi...   \n",
            "9996  Basic knowledge in value, no degree required. ...   \n",
            "9997  Basic knowledge in during, no degree required....   \n",
            "9998  Basic knowledge in can, no degree required. Fl...   \n",
            "9999  Basic knowledge in pick, no degree required. F...   \n",
            "\n",
            "                                       company_profile           location  \\\n",
            "0                  Rivera and Sons - Established 2022.       West Jeffrey   \n",
            "1        Davidson, Jones and Gomez - Established 2003.  Lake Meredithberg   \n",
            "2                        Allen Ltd - Established 1998.     Lake Cathybury   \n",
            "3                       Forbes Ltd - Established 1990.  South Matthewstad   \n",
            "4     Jennings, Martin and Sanchez - Established 1975.    East Rhondafurt   \n",
            "...                                                ...                ...   \n",
            "9995                Olson-Williams - Established 2017.          Paulabury   \n",
            "9996                 Moreno-Pruitt - Established 2016.     Moraleschester   \n",
            "9997    Lewis, Patterson and Cowan - Established 1979.     Christinemouth   \n",
            "9998                Diaz-Wilkerson - Established 2019.  Lake Meredithberg   \n",
            "9999      Sanders, Sanchez and Cox - Established 2024.       Samanthaland   \n",
            "\n",
            "        salary_range employment_type     industry                   benefits  \\\n",
            "0     $55016-$100476      Internship           IT                 Free meals   \n",
            "1      $53438-$93138       Part-Time      Finance             Flexible hours   \n",
            "2     $45584-$105229       Part-Time           IT                Free travel   \n",
            "3     $66188-$139621       Full-Time    Education                Free travel   \n",
            "4     $32183-$115012       Temporary       Retail             Flexible hours   \n",
            "...              ...             ...          ...                        ...   \n",
            "9995  $39450-$149734       Full-Time       Retail                 Free meals   \n",
            "9996  $49324-$111597       Part-Time           IT              Sign-on bonus   \n",
            "9997   $41346-$89686       Full-Time    Education  Remote work opportunities   \n",
            "9998  $65604-$149614        Contract      Finance             Flexible hours   \n",
            "9999  $56437-$112301       Temporary  Real Estate                 Free meals   \n",
            "\n",
            "      fraudulent  \n",
            "0              1  \n",
            "1              1  \n",
            "2              1  \n",
            "3              1  \n",
            "4              1  \n",
            "...          ...  \n",
            "9995           1  \n",
            "9996           1  \n",
            "9997           1  \n",
            "9998           1  \n",
            "9999           1  \n",
            "\n",
            "[10000 rows x 10 columns],                                                   title        label  \\\n",
            "0     Full Time New Job Positions .Net, .Netcore, Fl...  Premium Job   \n",
            "1       Full Time Senior Web Developer Jobs in Pakistan  Premium Job   \n",
            "2           Full Time Russian Speakers Jobs in Pakistan  Premium Job   \n",
            "3     Full Time Customer Support Specialist - Intern...  Premium Job   \n",
            "4     Full Time English Speaker - International Busi...  Premium Job   \n",
            "...                                                 ...          ...   \n",
            "6675  Full Time Senior Software Engineer  Job in Pak...          NaN   \n",
            "6676  Full Time Commercial Experience Executive Job ...          NaN   \n",
            "6677  Full Time Business Development Executive Job i...          NaN   \n",
            "6678  Full Time 3D Modeler / CG Artist Game Jobs in ...          NaN   \n",
            "6679  Full Time Bidding Expert / Social Media Market...          NaN   \n",
            "\n",
            "                                 Company Name        Job Type  \\\n",
            "0                   Nayel Solutions, Pakistan  Full Time Jobs   \n",
            "1     Eurosoft Tech Private Limited, Pakistan  Full Time Jobs   \n",
            "2                         ICM JAPAN, Pakistan  Full Time Jobs   \n",
            "3                              ibex, Pakistan  Full Time Jobs   \n",
            "4                         ICM JAPAN, Pakistan   Full Time Job   \n",
            "...                                       ...             ...   \n",
            "6675                       KnovaSol, Pakistan   Full Time Job   \n",
            "6676                                      NaN   Full Time Job   \n",
            "6677                  Loop Brackets, Pakistan   Full Time Job   \n",
            "6678            Super Duper Studio , Pakistan  Full Time Jobs   \n",
            "6679            Super Duper Studio , Pakistan  Full Time Jobs   \n",
            "\n",
            "          Experience Required              Department  \\\n",
            "0            2 Years Job Exp.                 IT Jobs   \n",
            "1            2 Years Job Exp.                 IT Jobs   \n",
            "2                    < 1 Year   Customer Service Jobs   \n",
            "3     Job for Fresh Graduates   Customer Service Jobs   \n",
            "4                    < 1 Year    Customer Service Job   \n",
            "...                       ...                     ...   \n",
            "6675         3 Years Job Exp.   Computer Software Job   \n",
            "6676         2 Years Job Exp.               Admin Job   \n",
            "6677         2 Years Job Exp.   Computer Software Job   \n",
            "6678         2 Years Job Exp.  Computer Software Jobs   \n",
            "6679  Job for Fresh Graduates  Computer Software Jobs   \n",
            "\n",
            "                                            description       City  \\\n",
            "0     New Job Positions .net, .netcore, flutter, Tea...  Islamabad   \n",
            "1     We are looking for an experienced Web Develope...    Karachi   \n",
            "2     International clients dealing exposure (B2B).S...    Karachi   \n",
            "3     Responsible for acting as a liaison between ou...  Islamabad   \n",
            "4     International clients dealing exposure (B2B) a...    Karachi   \n",
            "...                                                 ...        ...   \n",
            "6675  We required services of Senior Software Engine...  Islamabad   \n",
            "6676  As one of the leading employers in the country...     Multan   \n",
            "6677  The ideal candidate will have experience in al...     Lahore   \n",
            "6678  Must be able to create 3D Game Environments an...     Lahore   \n",
            "6679  Candidate Shall Be Expert in Getting Work from...     Lahore   \n",
            "\n",
            "     Date Posted  fraudulent  \n",
            "0      12-Mar-21           0  \n",
            "1      12-Mar-21           0  \n",
            "2      12-Mar-21           0  \n",
            "3      09-Mar-21           0  \n",
            "4      05-Mar-21           0  \n",
            "...          ...         ...  \n",
            "6675   30-Dec-20           0  \n",
            "6676   29-Dec-20           0  \n",
            "6677   29-Dec-20           0  \n",
            "6678   29-Dec-20           0  \n",
            "6679   29-Dec-20           0  \n",
            "\n",
            "[6680 rows x 10 columns],       Unnamed: 0                  title  \\\n",
            "0              0      Flutter Developer   \n",
            "1              1       Django Developer   \n",
            "2              2       Machine Learning   \n",
            "3              3          iOS Developer   \n",
            "4              4   Full Stack Developer   \n",
            "...          ...                    ...   \n",
            "2272        2399      Backend Developer   \n",
            "2273        2400   Full Stack Developer   \n",
            "2274        2401  Network Administrator   \n",
            "2275        2402       Machine Learning   \n",
            "2276        2403   Full Stack Developer   \n",
            "\n",
            "                                            description  fraudulent  \n",
            "0     We are looking for hire experts flutter develo...           0  \n",
            "1     PYTHON/DJANGO (Developer/Lead) - Job Code(PDJ ...           0  \n",
            "2     Data Scientist (Contractor)\\n\\nBangalore, IN\\n...           0  \n",
            "3     JOB DESCRIPTION:\\n\\nStrong framework outside o...           0  \n",
            "4     job responsibility full stack engineer – react...           0  \n",
            "...                                                 ...         ...  \n",
            "2272  Job Summary\\nPublished on : 26 days ago\\nVacan...           0  \n",
            "2273  business entity cisco umbrella focus cloud-bas...           0  \n",
            "2274  Urgently reqd in a college in Mohali\\nNetwork ...           0  \n",
            "2275  Key Responsibilities: Team leads for small or ...           0  \n",
            "2276  leslie hindman auctioneer one nation 's leadin...           0  \n",
            "\n",
            "[2277 rows x 4 columns]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = df['fraudulent'].value_counts()\n",
        "print(\"\\nClass Distribution:\\n\", class_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbacVqoxpyz1",
        "outputId": "de255da3-f032-489d-e1d7-902ccd28505e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class Distribution:\n",
            " fraudulent\n",
            "1    10000\n",
            "0     8957\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imbalance_ratio = class_counts.max() / class_counts.min()\n",
        "print(f\"\\nImbalance Ratio: {imbalance_ratio:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5v7elXy4qD0l",
        "outputId": "02fb0814-3e56-441e-ca2b-2bc9fc53dade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Imbalance Ratio: 1.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if imbalance_ratio > 1.5:\n",
        "    print(\"\\nApplying SMOTE to balance classes...\")\n",
        "    vectorizer = TfidfVectorizer(max_features=5000)\n",
        "    X_tfidf = vectorizer.fit_transform(X)\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_resampled, y_resampled = smote.fit_resample(X_tfidf, y)\n",
        "    X_resampled_text = X.iloc[X_resampled.indices]\n",
        "    print(\"SMOTE applied successfully!\")\n",
        "else:\n",
        "    print(\"No significant class imbalance detected. Proceeding without SMOTE.\")\n",
        "    X_resampled_text = X\n",
        "    y_resampled = y"
      ],
      "metadata": {
        "id": "yJ7BGQLsp9RA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "500f266a-14d7-46b6-b9f6-ea40e395dd65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No significant class imbalance detected. Proceeding without SMOTE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Ensure X_resampled_text exists (Convert to list if necessary)\n",
        "if isinstance(X_resampled_text, pd.Series):\n",
        "    X_resampled_text = X_resampled_text.tolist()\n",
        "tokenized_inputs = tokenizer(\n",
        "    list(X_resampled_text),\n",
        "    padding=\"longest\",\n",
        "    truncation=True,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "print(f\"\\nTokenized Input IDs Shape: {tokenized_inputs['input_ids'].shape}\")\n",
        "print(f\"Sample Tokenized Output:\\n{tokenized_inputs['input_ids'][0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "fUee7_4BqO3J",
        "outputId": "e03b775e-2019-4889-d141-7ebc07ae18bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'RobertaTokenizer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2b0dea6818b4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRobertaTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"roberta-base\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Ensure X_resampled_text exists (Convert to list if necessary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_resampled_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX_resampled_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_resampled_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'RobertaTokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "y_encoder = LabelEncoder()\n",
        "y_labels = torch.tensor(y_encoder.fit_transform(y_resampled), dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "EeqQeEAXqTH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " y_tensor = torch.tensor(y_resampled.values, dtype=torch.long)"
      ],
      "metadata": {
        "id": "HZOyHRbiqkfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = JobPostingDataset(tokenized_inputs, y_tensor)\n",
        "print(f\"Total samples in dataset: {len(dataset)}\")\n",
        "print(f\"Sample data: {dataset[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbp_Zzt8qnVp",
        "outputId": "d098548a-e14b-4ce9-cb76-d4dcd3e4767b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples in dataset: 18957\n",
            "Sample data: {'input_ids': tensor([    0,   448, 13589,   474,  9008, 10617,  1305,   461,   686,   900,\n",
            "            4,  7535,    68, 31830,    73,  3583,   328,  5902, 30771,  5947,\n",
            "            4,  4493,   122,    23, 44009,  2518,  1039, 14551,     4,   175,\n",
            "            4,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor(1)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_set, val_set = torch.utils.data.random_split(dataset, [train_size, val_size])"
      ],
      "metadata": {
        "id": "y4aHijkzqpUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class RoBERTaBiLSTM(nn.Module):\n",
        "    def __init__(self, roberta_model='roberta-base', hidden_dim=256, num_classes=2, dropout=0.3):\n",
        "        super(RoBERTaBiLSTM, self).__init__()\n",
        "        self.roberta = RobertaModel.from_pretrained(roberta_model)\n",
        "        self.lstm = nn.LSTM(input_size=768, hidden_size=hidden_dim, bidirectional=True, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):  # Added labels argument\n",
        "        with torch.no_grad():\n",
        "            roberta_output = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        lstm_input = roberta_output.last_hidden_state\n",
        "        lstm_out, _ = self.lstm(lstm_input)\n",
        "        lstm_out = lstm_out[:, -1, :]\n",
        "        output = self.fc(self.dropout(lstm_out))\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:  # Calculate loss if labels are provided\n",
        "            loss_fct = nn.CrossEntropyLoss()  # Using CrossEntropyLoss for classification\n",
        "            loss = loss_fct(output, labels)\n",
        "\n",
        "        return (loss, output) if loss is not None else output\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FCM7xqRcqr6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import Trainer, TrainingArguments\n",
        "model = RoBERTaBiLSTM()\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=500,\n",
        "    save_steps=1000,\n",
        "    report_to=\"none\",\n",
        "    learning_rate= 5e-5,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "2f50b7b91e8d4ad6a129026e6e01f3f7",
            "1ff3004da7504c648a257c09348a96bb",
            "9da6e2459ae9427495599fd763e3b20d",
            "f67bdebe7a6e49d987db549ebe8e426e",
            "a7433ebf312743ddad6eb9a9f895e786",
            "4a163cab35534f05a9a3eb2d7707f723",
            "1faebcb1d061419c82c189c839c90a9e",
            "a2d73ece473d458b8158a44080d9424e",
            "e2e88235b1674eb3ab164e0e13b6e1d3",
            "b16785b4c5c04496ab01690219e27325",
            "627cebc8a7134673aef7e85c691e78fa"
          ]
        },
        "id": "8Fx02DQkquFH",
        "outputId": "4f494139-d2e2-4cc1-8be3-9556b9d4059c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f50b7b91e8d4ad6a129026e6e01f3f7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\")\n",
        "\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        logits = outputs[1]\n",
        "        loss_fct = nn.CrossEntropyLoss()\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_set,\n",
        "    eval_dataset=val_set\n",
        ")"
      ],
      "metadata": {
        "id": "R849K1fsqxNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBE5HA0qq3t3",
        "outputId": "42b40054-8072-47db-9798-b1ab7ff9e319"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.8)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.25.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.10.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.22.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "model = RoBERTaBiLSTM()\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_set,\n",
        "    eval_dataset=val_set\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNzwBYfeq9TA",
        "outputId": "0c44619c-3dbb-4530-8134-17983725b719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "eDhlZj8jrFgx",
        "outputId": "b7e5f295-33cf-4cf7-a7c7-3fb07849d209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11376' max='11376' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11376/11376 35:49, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.002900</td>\n",
              "      <td>0.020066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=11376, training_loss=0.014734162980094277, metrics={'train_runtime': 2151.0782, 'train_samples_per_second': 21.15, 'train_steps_per_second': 5.289, 'total_flos': 0.0, 'train_loss': 0.014734162980094277, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/MyDrive/model', exist_ok=True)\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/model/model_state_dict.pth')\n",
        "tokenizer.save_pretrained('/content/drive/MyDrive/model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMgb28xQrQHD",
        "outputId": "222de2c2-9e3f-4efb-e618-17327f85229e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/model/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/model/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/model/vocab.json',\n",
              " '/content/drive/MyDrive/model/merges.txt',\n",
              " '/content/drive/MyDrive/model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  print(\"\\nEvaluating the model on validation data...\")\n",
        "  eval_results = trainer.evaluate()\n",
        "  print(eval_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "lKlhFhX_z7fi",
        "outputId": "2512387f-0c8e-477d-be08-e4950c857c84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating the model on validation data...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='948' max='948' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [948/948 01:58]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 1.530390181869734e-05, 'eval_runtime': 118.8069, 'eval_samples_per_second': 31.917, 'eval_steps_per_second': 7.979, 'epoch': 3.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if trainer.state.log_history and 'loss' in trainer.state.log_history[-1]:\n",
        "    training_loss = trainer.state.log_history[-1]['loss']\n",
        "else:\n",
        "    training_loss = None\n",
        "validation_loss = eval_results.get('eval_loss', None)\n",
        "print(f\"Training Loss: {training_loss:.4f}\" if training_loss is not None else \"Training Loss not available\")\n",
        "print(f\"Validation Loss: {validation_loss:.4f}\" if validation_loss is not None else \"Validation Loss not available\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6VHyxJpz_ZZ",
        "outputId": "216427bd-eae3-4281-aef3-a939245d998e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss not available\n",
            "Validation Loss: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "predictions_output = trainer.predict(val_set)\n",
        "\n",
        "\n",
        "logits = predictions_output.predictions\n",
        "labels = predictions_output.label_ids\n",
        "\n",
        "\n",
        "predictions = torch.argmax(torch.tensor(logits), dim=-1).numpy()\n",
        "\n",
        "accuracy = accuracy_score(labels, predictions)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"weighted\")\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "V30DkpTV0yzo",
        "outputId": "e7bf4f43-6c23-4e2f-afc0-9c3c3e011c8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-score: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile predictor1.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "\n",
        "class RoBERTa_LSTM(nn.Module):\n",
        "    def __init__(self, roberta_model, hidden_dim=256, num_labels=2):\n",
        "        super(RoBERTa_LSTM, self).__init__()\n",
        "        self.roberta = RobertaModel.from_pretrained(roberta_model)\n",
        "        self.lstm = nn.LSTM(input_size=self.roberta.config.hidden_size, hidden_size=hidden_dim,\n",
        "                            batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, num_labels)\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        with torch.no_grad():\n",
        "            roberta_output = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        lstm_output, _ = self.lstm(roberta_output.last_hidden_state)\n",
        "        logits = self.fc(lstm_output[:, -1, :])\n",
        "        return logits\n",
        "\n",
        "\n",
        "# Load Model and Tokenizer\n",
        "MODEL_PATH = \"/content/drive/MyDrive/model/model_state_dict.pth\"\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RoBERTa_LSTM(\"roberta-base\")\n",
        "model.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device(\"cpu\")))\n",
        "model.eval()\n",
        "\n",
        "def predict_job_fraud(job_description):\n",
        "    inputs = tokenizer(job_description, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
        "        probabilities = torch.nn.functional.softmax(outputs, dim=-1)\n",
        "\n",
        "    predicted_label = torch.argmax(probabilities, dim=-1).item()\n",
        "    confidence = probabilities.max().item()\n",
        "\n",
        "    return \"Fake Job\" if predicted_label == 1 else \"Real Job\", confidence\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpWLqAJ8CcEI",
        "outputId": "bcf637d1-1784-4b65-dd60-d4972ce696ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing predictor1.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job_posting = input(\"Enter the job description: \")\n",
        "\n",
        "prediction, confidence = predict_job_fraud(job_posting)\n",
        "\n",
        "print(f\"\\nPrediction: {prediction} (Confidence: {confidence:.2f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQxsrHO5DBQC",
        "outputId": "a4e46028-499a-4a19-fc03-686d90c9dce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the job description: Arm drive court sure vote. Earn $5000/week! Immediate hiring. Contact now at david27@gmail.com.\n",
            "\n",
            "Prediction: Fake Job (Confidence: 1.00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job_posting = input(\"Enter the job description: \")\n",
        "\n",
        "prediction, confidence = predict_job_fraud(job_posting)\n",
        "\n",
        "print(f\"\\nPrediction: {prediction} (Confidence: {confidence:.2f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6CBbN9LDIJo",
        "outputId": "a8d70821-83b3-4951-efc9-a1f70744fe0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the job description: This job is a remote working opportunity. We are a small service company located in Texas. We specialize in piano tuning, moving, repair, and restoration.Job Benefits Ability to work from home with flexible scheduling, only 1-2 hours of fixed schedul\n",
            "\n",
            "Prediction: Real Job (Confidence: 1.00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0FicGL0_D8Cv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}